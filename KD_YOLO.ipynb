{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOGfsRzdTn3gFxkrKBm2M8Z"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# YOLOv8 Knowledge Distillation vs Baseline\n",
        "# ==============================================================\n",
        "\n",
        "# 0) تنظیمات\n",
        "DRIVE = True\n",
        "DRIVE_ROOT = '/content/drive/MyDrive/yolov8_kd'\n",
        "TRAIN_RATIO = 0.8\n",
        "EPOCHS = 15\n",
        "\n",
        "# 1) نصب و دانلود دیتاست\n",
        "!pip install -q --upgrade pip\n",
        "!pip install -q ultralytics\n",
        "\n",
        "import os, random, shutil, yaml\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "\n",
        "if not Path('coco128').exists():\n",
        "    !wget -q https://ultralytics.com/assets/coco128.zip -O coco128.zip\n",
        "    !unzip -q coco128.zip -d ./coco128\n",
        "\n",
        "# اتصال به Google Drive\n",
        "if DRIVE:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    os.makedirs(DRIVE_ROOT, exist_ok=True)\n",
        "\n",
        "# پیدا کردن مسیر اصلی دیتاست\n",
        "possible_roots = [Path('coco128'), Path('coco128/coco128'), Path('coco128/coco128/coco128')]\n",
        "DATA_ROOT = None\n",
        "for p in possible_roots:\n",
        "    if (p / 'images' / 'train2017').exists():\n",
        "        DATA_ROOT = p\n",
        "        break\n",
        "if DATA_ROOT is None:\n",
        "    raise RuntimeError(\"Dataset root not found.\")\n",
        "print(f\"Using DATA_ROOT = {DATA_ROOT}\")\n",
        "\n",
        "# 2) ساخت train/val split (۸۰/۲۰)\n",
        "split_root = Path('coco128_split')\n",
        "if split_root.exists():\n",
        "    shutil.rmtree(split_root)\n",
        "for sub in ['images/train', 'images/val', 'labels/train', 'labels/val']:\n",
        "    (split_root / sub).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "images = sorted((DATA_ROOT / 'images' / 'train2017').glob('*.jpg'))\n",
        "random.shuffle(images)\n",
        "split_idx = int(len(images) * TRAIN_RATIO)\n",
        "train_imgs = images[:split_idx]\n",
        "val_imgs = images[split_idx:]\n",
        "\n",
        "for img_path in train_imgs:\n",
        "    lbl_path = DATA_ROOT / 'labels' / 'train2017' / (img_path.stem + '.txt')\n",
        "    shutil.copy(img_path, split_root / 'images/train')\n",
        "    if lbl_path.exists():\n",
        "        shutil.copy(lbl_path, split_root / 'labels/train')\n",
        "\n",
        "for img_path in val_imgs:\n",
        "    lbl_path = DATA_ROOT / 'labels' / 'train2017' / (img_path.stem + '.txt')\n",
        "    shutil.copy(img_path, split_root / 'images/val')\n",
        "    if lbl_path.exists():\n",
        "        shutil.copy(lbl_path, split_root / 'labels/val')\n",
        "\n",
        "print(f\"Train: {len(train_imgs)} images, Val: {len(val_imgs)} images\")\n",
        "\n",
        "# 3) ساخت yaml برای baseline\n",
        "nc = 80\n",
        "names = {i: f'class{i}' for i in range(nc)}\n",
        "BASELINE_YAML = Path('dataset_baseline.yaml')\n",
        "yaml.safe_dump({\n",
        "    'path': str(split_root.absolute()),\n",
        "    'train': 'images/train',\n",
        "    'val': 'images/val',\n",
        "    'nc': nc,\n",
        "    'names': names\n",
        "}, open(BASELINE_YAML, 'w'))\n",
        "\n",
        "# 4) بارگذاری مدل Teacher و Student\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "teacher = YOLO('yolov8x.pt').to(DEVICE)\n",
        "teacher.eval()\n",
        "student = YOLO('yolov8n.pt').to(DEVICE)\n",
        "\n",
        "# 5) اجرای baseline\n",
        "baseline_dir = Path(DRIVE_ROOT) / 'baseline_student'\n",
        "student.train(\n",
        "    data=str(BASELINE_YAML),\n",
        "    epochs=EPOCHS,\n",
        "    imgsz=640,\n",
        "    project=baseline_dir.parent,\n",
        "    name=baseline_dir.name,\n",
        "    exist_ok=True\n",
        ")\n",
        "baseline_best = baseline_dir / 'weights' / 'best.pt'\n",
        "baseline_metrics = YOLO(str(baseline_best)).val(data=str(BASELINE_YAML), split='val')\n",
        "\n",
        "# 6) تولید KD labels برای train فقط\n",
        "import cv2\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from ultralytics.utils.ops import xyxy2xywh\n",
        "\n",
        "TEACHER_CONF = 0.35\n",
        "MAX_PRED_PER_IMAGE = 300\n",
        "KD_LABELS_TRAIN = split_root / 'labels_kd' / 'train'\n",
        "if KD_LABELS_TRAIN.exists():\n",
        "    shutil.rmtree(KD_LABELS_TRAIN.parent)\n",
        "KD_LABELS_TRAIN.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def read_label_file(path: Path):\n",
        "    return [l.strip() for l in path.read_text().splitlines()] if path.exists() else []\n",
        "\n",
        "def write_label_file(path: Path, lines):\n",
        "    path.write_text('\\n'.join(lines) + ('\\n' if lines else ''))\n",
        "\n",
        "for img_path in tqdm(sorted((split_root / 'images/train').glob('*.jpg')), desc='KD labels'):\n",
        "    orig_lines = read_label_file(split_root / 'labels/train' / (img_path.stem + '.txt'))\n",
        "    results = teacher.predict(source=str(img_path), conf=TEACHER_CONF, imgsz=640, device=DEVICE, verbose=False)\n",
        "    r = results[0]\n",
        "    kd_lines = []\n",
        "    if r.boxes is not None and len(r.boxes):\n",
        "        xyxy = r.boxes.xyxy.cpu().numpy()\n",
        "        confs = r.boxes.conf.cpu().numpy()\n",
        "        cls = r.boxes.cls.cpu().numpy().astype(int)\n",
        "        xywh = xyxy2xywh(torch.tensor(xyxy)).numpy()\n",
        "        h, w = cv2.imread(str(img_path)).shape[:2]\n",
        "        xywh[:, 0] /= w; xywh[:, 1] /= h; xywh[:, 2] /= w; xywh[:, 3] /= h\n",
        "        keep_idx = np.where(confs >= TEACHER_CONF)[0][:MAX_PRED_PER_IMAGE]\n",
        "        for i in keep_idx:\n",
        "            xcen, ycen, bw, bh = xywh[i].tolist()\n",
        "            kd_lines.append(f\"{cls[i]} {xcen:.6f} {ycen:.6f} {bw:.6f} {bh:.6f}\")\n",
        "    write_label_file(KD_LABELS_TRAIN / (img_path.stem + '.txt'), orig_lines + kd_lines)\n",
        "\n",
        "# 7) ساخت yaml برای KD\n",
        "KD_YAML = Path('dataset_kd.yaml')\n",
        "yaml.safe_dump({\n",
        "    'path': str(split_root.absolute()),\n",
        "    'train': 'images/train',\n",
        "    'val': 'images/val',\n",
        "    'nc': nc,\n",
        "    'names': names\n",
        "}, open(KD_YAML, 'w'))\n",
        "\n",
        "# جایگزینی labelهای train با KD\n",
        "shutil.rmtree(split_root / 'labels/train')\n",
        "shutil.copytree(KD_LABELS_TRAIN, split_root / 'labels/train')\n",
        "\n",
        "# 8) آموزش Student با KD\n",
        "kd_dir = Path(DRIVE_ROOT) / 'kd_student'\n",
        "student = YOLO('yolov8n.pt').to(DEVICE)\n",
        "student.train(\n",
        "    data=str(KD_YAML),\n",
        "    epochs=EPOCHS,\n",
        "    imgsz=640,\n",
        "    project=kd_dir.parent,\n",
        "    name=kd_dir.name,\n",
        "    exist_ok=True\n",
        ")\n",
        "kd_best = kd_dir / 'weights' / 'best.pt'\n",
        "kd_metrics = YOLO(str(kd_best)).val(data=str(BASELINE_YAML), split='val')\n",
        "\n",
        "# 9) مقایسه mAP50\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "results_df = pd.DataFrame({\n",
        "    'model': ['baseline_student', 'kd_student'],\n",
        "    'mAP50': [baseline_metrics.box.map50, kd_metrics.box.map50]\n",
        "})\n",
        "print(results_df)\n",
        "\n",
        "plt.bar(results_df['model'], results_df['mAP50'])\n",
        "plt.ylabel('mAP@50')\n",
        "plt.title('Baseline vs KD')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oq2OdIYxFrXY",
        "outputId": "ce5b9ebb-baa4-4d15-aec0-1080c6dbce9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Using DATA_ROOT = coco128/coco128\n",
            "Train: 102 images, Val: 26 images\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8x.pt to 'yolov8x.pt': 100%|██████████| 131M/131M [00:01<00:00, 108MB/s] \n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100%|██████████| 6.25M/6.25M [00:00<00:00, 61.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=dataset_baseline.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=baseline_student, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/yolov8_kd, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/yolov8_kd/baseline_student, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100%|██████████| 755k/755k [00:00<00:00, 19.0MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100%|██████████| 5.35M/5.35M [00:00<00:00, 79.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1354.1±499.4 MB/s, size: 74.1 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/coco128_split/labels/train... 101 images, 1 backgrounds, 0 corrupt: 100%|██████████| 102/102 [00:00<00:00, 2537.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/coco128_split/labels/train.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 331.4±125.7 MB/s, size: 45.3 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/coco128_split/labels/val... 25 images, 1 backgrounds, 0 corrupt: 100%|██████████| 26/26 [00:00<00:00, 1528.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/coco128_split/labels/val.cache\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/drive/MyDrive/yolov8_kd/baseline_student/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/yolov8_kd/baseline_student\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/15      2.63G      1.153      1.571      1.259         93        640: 100%|██████████| 7/7 [00:05<00:00,  1.36it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.762      0.541      0.661      0.498\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/15      3.16G      1.165      1.502      1.279         50        640: 100%|██████████| 7/7 [00:01<00:00,  4.29it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.787      0.546      0.656      0.493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/15      3.19G      1.195      1.426      1.252        114        640: 100%|██████████| 7/7 [00:01<00:00,  4.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.813      0.536      0.655      0.496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/15       3.2G       1.11      1.242      1.199         79        640: 100%|██████████| 7/7 [00:01<00:00,  4.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.798      0.546      0.655      0.496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/15      3.22G       1.16      1.404      1.232        124        640: 100%|██████████| 7/7 [00:02<00:00,  3.38it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.793      0.529       0.65      0.491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/15      3.24G      1.164      1.312      1.212         44        640: 100%|██████████| 7/7 [00:03<00:00,  2.20it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.803      0.526      0.652       0.49\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/15      3.26G       1.11      1.233      1.174         54        640: 100%|██████████| 7/7 [00:01<00:00,  5.09it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.799      0.523      0.649      0.482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/15      3.28G       1.12      1.196      1.185         32        640: 100%|██████████| 7/7 [00:01<00:00,  5.25it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.787       0.52       0.65      0.481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/15      3.29G      1.104      1.204      1.167         47        640: 100%|██████████| 7/7 [00:01<00:00,  4.93it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.756      0.513      0.632      0.477\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/15      3.31G        1.1      1.205      1.173         36        640: 100%|██████████| 7/7 [00:01<00:00,  4.68it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.762      0.525      0.635      0.472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/15      3.33G      1.099      1.176      1.165         27        640: 100%|██████████| 7/7 [00:01<00:00,  3.53it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193       0.76      0.522      0.636       0.47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/15      3.35G      1.041      1.133      1.126         46        640: 100%|██████████| 7/7 [00:01<00:00,  4.88it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.98it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.694      0.533      0.631      0.471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/15      3.37G      1.113      1.061      1.159         55        640: 100%|██████████| 7/7 [00:01<00:00,  5.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.37it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.695      0.517       0.63       0.47\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/15      3.38G      1.067      1.129      1.137         62        640: 100%|██████████| 7/7 [00:01<00:00,  5.12it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.81it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.686      0.513      0.625      0.468\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/15       3.4G      1.125      1.193      1.199         48        640: 100%|██████████| 7/7 [00:01<00:00,  4.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.649      0.525      0.628      0.469\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "15 epochs completed in 0.012 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/yolov8_kd/baseline_student/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from /content/drive/MyDrive/yolov8_kd/baseline_student/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating /content/drive/MyDrive/yolov8_kd/baseline_student/weights/best.pt...\n",
            "Ultralytics 8.3.177 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.761      0.541      0.663      0.499\n",
            "                class0         16         80      0.784       0.55      0.686      0.456\n",
            "                class2          2          5      0.561        0.2      0.205      0.139\n",
            "                class3          1          1      0.923          1      0.995      0.597\n",
            "                class8          1          1          0          0      0.332      0.265\n",
            "                class9          1          1          1          0          0          0\n",
            "               class13          2          3      0.724          1       0.83      0.581\n",
            "               class14          1          8          1      0.761      0.935      0.546\n",
            "               class15          1          1      0.712          1      0.995      0.995\n",
            "               class16          2          2          1      0.894      0.995      0.407\n",
            "               class17          1          2      0.727          1      0.995      0.529\n",
            "               class20          1          2      0.623        0.5      0.828      0.419\n",
            "               class22          1          1      0.655          1      0.995      0.995\n",
            "               class24          1          1          1          0     0.0284     0.0165\n",
            "               class25          1          1      0.667          1      0.995      0.995\n",
            "               class26          1          1          1          0      0.142     0.0995\n",
            "               class27          1          1      0.599          1      0.995      0.995\n",
            "               class29          1          1       0.61          1      0.995      0.796\n",
            "               class31          1          6      0.797      0.657      0.762      0.468\n",
            "               class32          1          1       0.78          1      0.995      0.497\n",
            "               class33          1          6      0.793      0.643      0.653      0.237\n",
            "               class34          2          2          1          0     0.0215    0.00215\n",
            "               class35          2          5      0.678        0.2        0.2       0.18\n",
            "               class38          1          1          1          0     0.0262     0.0117\n",
            "               class41          1          3          1      0.615      0.741      0.632\n",
            "               class42          2          2          1          0     0.0144     0.0115\n",
            "               class43          2          6      0.824      0.167      0.458      0.117\n",
            "               class44          1         11          1          0     0.0622     0.0375\n",
            "               class45          2          4      0.722          1      0.845      0.664\n",
            "               class49          1          4          1          0      0.945      0.625\n",
            "               class50          1          1      0.279          1      0.995      0.895\n",
            "               class51          1          2      0.686          1      0.995      0.945\n",
            "               class53          1          1      0.664          1      0.995      0.995\n",
            "               class54          1          1      0.664          1      0.995      0.895\n",
            "               class56          1         13      0.518          1      0.575      0.336\n",
            "               class58          1          1      0.758          1      0.995      0.895\n",
            "               class63          1          2          1          0      0.995      0.796\n",
            "               class67          2          3          0          0      0.108     0.0644\n",
            "               class68          1          1      0.462          1      0.995      0.995\n",
            "               class71          1          2          1          0      0.221     0.0595\n",
            "               class74          1          1          1          0      0.995      0.895\n",
            "               class79          1          2          1          0      0.663      0.356\n",
            "Speed: 0.2ms preprocess, 2.4ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/yolov8_kd/baseline_student\u001b[0m\n",
            "Ultralytics 8.3.177 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 976.1±111.6 MB/s, size: 39.6 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/coco128_split/labels/val.cache... 25 images, 1 backgrounds, 0 corrupt: 100%|██████████| 26/26 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193       0.75      0.538      0.665      0.498\n",
            "                class0         16         80      0.779      0.588      0.721      0.462\n",
            "                class2          2          5      0.523        0.2      0.206       0.16\n",
            "                class3          1          1      0.884          1      0.995      0.597\n",
            "                class8          1          1          1          0      0.332      0.265\n",
            "                class9          1          1          1          0          0          0\n",
            "               class13          2          3      0.732          1       0.83      0.581\n",
            "               class14          1          8          1      0.768      0.955      0.564\n",
            "               class15          1          1      0.674          1      0.995      0.796\n",
            "               class16          2          2      0.631        0.5      0.828      0.347\n",
            "               class17          1          2      0.696          1      0.995      0.525\n",
            "               class20          1          2      0.603        0.5      0.828      0.419\n",
            "               class22          1          1      0.644          1      0.995      0.995\n",
            "               class24          1          1          1          0     0.0369     0.0272\n",
            "               class25          1          1      0.651          1      0.995      0.995\n",
            "               class26          1          1          1          0      0.142     0.0995\n",
            "               class27          1          1      0.582          1      0.995      0.995\n",
            "               class29          1          1      0.598          1      0.995      0.895\n",
            "               class31          1          6       0.77      0.833      0.835       0.58\n",
            "               class32          1          1      0.886          1      0.995      0.497\n",
            "               class33          1          6        0.8      0.665      0.683      0.249\n",
            "               class34          2          2          1          0     0.0104    0.00104\n",
            "               class35          2          5      0.681        0.2        0.2       0.18\n",
            "               class38          1          1          1          0     0.0255     0.0116\n",
            "               class41          1          3      0.514      0.361      0.665      0.573\n",
            "               class42          2          2          1          0     0.0187     0.0149\n",
            "               class43          2          6      0.543      0.167      0.589      0.156\n",
            "               class44          1         11          1          0     0.0558      0.032\n",
            "               class45          2          4      0.624          1      0.845      0.656\n",
            "               class49          1          4          1      0.278      0.995      0.624\n",
            "               class50          1          1      0.287          1      0.995      0.995\n",
            "               class51          1          2      0.577          1      0.995      0.945\n",
            "               class53          1          1      0.652          1      0.995      0.895\n",
            "               class54          1          1      0.628          1      0.995      0.895\n",
            "               class56          1         13        0.5          1      0.556      0.321\n",
            "               class58          1          1      0.736          1      0.995      0.895\n",
            "               class63          1          2          1          0      0.995      0.796\n",
            "               class67          2          3          0          0      0.116     0.0658\n",
            "               class68          1          1      0.551          1      0.995      0.995\n",
            "               class71          1          2          1          0      0.195     0.0611\n",
            "               class74          1          1          1          0      0.995      0.895\n",
            "               class79          1          2          1          0      0.663      0.342\n",
            "Speed: 0.2ms preprocess, 17.3ms inference, 0.0ms loss, 3.4ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "KD labels: 100%|██████████| 102/102 [00:06<00:00, 15.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=dataset_kd.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=15, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=kd_student, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/yolov8_kd, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/yolov8_kd/kd_student, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,157,200 parameters, 3,157,184 gradients, 8.9 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1711.8±151.8 MB/s, size: 74.1 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/coco128_split/labels/train... 102 images, 1 backgrounds, 0 corrupt: 100%|██████████| 102/102 [00:00<00:00, 2417.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/coco128_split/labels/train.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 363.1±197.0 MB/s, size: 45.3 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/coco128_split/labels/val.cache... 25 images, 1 backgrounds, 0 corrupt: 100%|██████████| 26/26 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Plotting labels to /content/drive/MyDrive/yolov8_kd/kd_student/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/drive/MyDrive/yolov8_kd/kd_student\u001b[0m\n",
            "Starting training for 15 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       1/15      2.97G      1.029      1.677      1.232        174        640: 100%|██████████| 7/7 [00:03<00:00,  1.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193       0.76      0.541      0.657      0.496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       2/15      3.13G      1.013      1.577       1.24         89        640: 100%|██████████| 7/7 [00:01<00:00,  4.31it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.93it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.832      0.533      0.654      0.489\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       3/15       3.3G      1.051      1.468      1.212        177        640: 100%|██████████| 7/7 [00:01<00:00,  4.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.16it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.828       0.54      0.657      0.492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       4/15      3.48G     0.9864      1.292      1.163        137        640: 100%|██████████| 7/7 [00:01<00:00,  4.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.784      0.549      0.657      0.488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       5/15      3.67G      1.005      1.454      1.187        230        640: 100%|██████████| 7/7 [00:02<00:00,  3.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  1.84it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.779      0.552      0.654      0.487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       6/15      3.67G      1.006      1.292      1.165         82        640: 100%|██████████| 7/7 [00:03<00:00,  2.16it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.798       0.55      0.655      0.486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       7/15      3.67G     0.9265      1.206      1.122         95        640: 100%|██████████| 7/7 [00:01<00:00,  4.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.784      0.526      0.647      0.482\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       8/15      3.67G     0.9459      1.206      1.118         61        640: 100%|██████████| 7/7 [00:01<00:00,  4.72it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.35it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.782      0.521      0.645       0.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       9/15      3.67G     0.9545      1.207      1.118         84        640: 100%|██████████| 7/7 [00:01<00:00,  4.96it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.773      0.532      0.642      0.479\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      10/15      3.67G     0.9293      1.215      1.112         65        640: 100%|██████████| 7/7 [00:01<00:00,  3.71it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.728      0.538      0.644      0.478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      11/15      3.67G     0.9024      1.155      1.092         53        640: 100%|██████████| 7/7 [00:01<00:00,  3.62it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.20it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.718      0.534      0.639      0.472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      12/15      3.67G     0.8799      1.135      1.083         85        640: 100%|██████████| 7/7 [00:01<00:00,  4.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.02it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193       0.73      0.534       0.64      0.473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      13/15      3.67G     0.9478      1.057        1.1         82        640: 100%|██████████| 7/7 [00:01<00:00,  5.24it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.714      0.524      0.638      0.474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      14/15      3.67G     0.9022      1.119      1.083        111        640: 100%|██████████| 7/7 [00:01<00:00,  4.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.723       0.52      0.632      0.472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "      15/15      3.67G     0.9853      1.196       1.16         84        640: 100%|██████████| 7/7 [00:01<00:00,  4.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.718      0.524       0.63      0.472\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "15 epochs completed in 0.011 hours.\n",
            "Optimizer stripped from /content/drive/MyDrive/yolov8_kd/kd_student/weights/last.pt, 6.5MB\n",
            "Optimizer stripped from /content/drive/MyDrive/yolov8_kd/kd_student/weights/best.pt, 6.5MB\n",
            "\n",
            "Validating /content/drive/MyDrive/yolov8_kd/kd_student/weights/best.pt...\n",
            "Ultralytics 8.3.177 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193       0.76      0.541      0.657      0.495\n",
            "                class0         16         80      0.781       0.55      0.686      0.456\n",
            "                class2          2          5      0.557        0.2      0.205      0.139\n",
            "                class3          1          1      0.928          1      0.995      0.597\n",
            "                class8          1          1          0          0      0.166      0.133\n",
            "                class9          1          1          1          0          0          0\n",
            "               class13          2          3      0.725          1       0.83      0.581\n",
            "               class14          1          8          1      0.761      0.935      0.546\n",
            "               class15          1          1      0.713          1      0.995      0.995\n",
            "               class16          2          2          1      0.895      0.995      0.405\n",
            "               class17          1          2      0.731          1      0.995      0.529\n",
            "               class20          1          2      0.624        0.5      0.828      0.419\n",
            "               class22          1          1      0.656          1      0.995      0.995\n",
            "               class24          1          1          1          0     0.0284     0.0167\n",
            "               class25          1          1      0.669          1      0.995      0.995\n",
            "               class26          1          1          1          0      0.124     0.0871\n",
            "               class27          1          1      0.602          1      0.995      0.995\n",
            "               class29          1          1      0.611          1      0.995      0.796\n",
            "               class31          1          6      0.796      0.654      0.762      0.467\n",
            "               class32          1          1      0.788          1      0.995      0.497\n",
            "               class33          1          6      0.793      0.644      0.654      0.237\n",
            "               class34          2          2          1          0          0          0\n",
            "               class35          2          5      0.678        0.2        0.2       0.18\n",
            "               class38          1          1          1          0     0.0249     0.0112\n",
            "               class41          1          3          1      0.614      0.741      0.632\n",
            "               class42          2          2          1          0     0.0146     0.0117\n",
            "               class43          2          6      0.748      0.167      0.451      0.114\n",
            "               class44          1         11          1          0     0.0606     0.0365\n",
            "               class45          2          4      0.734          1      0.845      0.648\n",
            "               class49          1          4          1          0      0.945      0.625\n",
            "               class50          1          1      0.279          1      0.995      0.895\n",
            "               class51          1          2      0.689          1      0.995      0.945\n",
            "               class53          1          1      0.665          1      0.995      0.995\n",
            "               class54          1          1      0.664          1      0.995      0.895\n",
            "               class56          1         13      0.519          1      0.556       0.33\n",
            "               class58          1          1      0.758          1      0.995      0.895\n",
            "               class63          1          2          1          0      0.995      0.796\n",
            "               class67          2          3          0          0      0.108     0.0644\n",
            "               class68          1          1      0.469          1      0.995      0.995\n",
            "               class71          1          2          1          0      0.199     0.0626\n",
            "               class74          1          1          1          0      0.995      0.895\n",
            "               class79          1          2          1          0      0.663      0.379\n",
            "Speed: 0.4ms preprocess, 2.4ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
            "Results saved to \u001b[1m/content/drive/MyDrive/yolov8_kd/kd_student\u001b[0m\n",
            "Ultralytics 8.3.177 🚀 Python-3.11.13 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,151,904 parameters, 0 gradients, 8.7 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1460.0±340.3 MB/s, size: 39.6 KB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/coco128_split/labels/val.cache... 25 images, 1 backgrounds, 0 corrupt: 100%|██████████| 26/26 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   all         26        193      0.748      0.541      0.663      0.497\n",
            "                class0         16         80      0.771      0.591      0.722      0.462\n",
            "                class2          2          5      0.519        0.2      0.206      0.159\n",
            "                class3          1          1      0.879          1      0.995      0.597\n",
            "                class8          1          1          1          0      0.249      0.199\n",
            "                class9          1          1          1          0          0          0\n",
            "               class13          2          3      0.727          1       0.83      0.581\n",
            "               class14          1          8          1      0.782      0.949       0.56\n",
            "               class15          1          1      0.669          1      0.995      0.796\n",
            "               class16          2          2      0.625        0.5      0.828      0.347\n",
            "               class17          1          2      0.695          1      0.995      0.525\n",
            "               class20          1          2      0.599        0.5      0.828      0.419\n",
            "               class22          1          1      0.642          1      0.995      0.995\n",
            "               class24          1          1          1          0     0.0369     0.0272\n",
            "               class25          1          1      0.648          1      0.995      0.995\n",
            "               class26          1          1          1          0      0.124     0.0871\n",
            "               class27          1          1      0.581          1      0.995      0.995\n",
            "               class29          1          1      0.595          1      0.995      0.895\n",
            "               class31          1          6      0.771      0.833      0.862      0.582\n",
            "               class32          1          1      0.885          1      0.995      0.497\n",
            "               class33          1          6      0.792      0.667      0.683      0.249\n",
            "               class34          2          2          1          0     0.0105    0.00105\n",
            "               class35          2          5      0.677        0.2        0.2       0.18\n",
            "               class38          1          1          1          0     0.0249     0.0112\n",
            "               class41          1          3      0.547      0.428      0.665      0.573\n",
            "               class42          2          2          1          0     0.0192     0.0153\n",
            "               class43          2          6      0.535      0.202      0.589      0.156\n",
            "               class44          1         11          1          0     0.0558      0.032\n",
            "               class45          2          4      0.622          1      0.845      0.656\n",
            "               class49          1          4          1      0.288      0.995      0.667\n",
            "               class50          1          1      0.282          1      0.995      0.995\n",
            "               class51          1          2      0.567          1      0.995      0.945\n",
            "               class53          1          1      0.648          1      0.995      0.895\n",
            "               class54          1          1      0.623          1      0.995      0.895\n",
            "               class56          1         13      0.497          1      0.556      0.321\n",
            "               class58          1          1      0.729          1      0.995      0.895\n",
            "               class63          1          2          1          0      0.995      0.796\n",
            "               class67          2          3          0          0      0.116     0.0658\n",
            "               class68          1          1      0.542          1      0.995      0.995\n",
            "               class71          1          2          1          0      0.201     0.0617\n",
            "               class74          1          1          1          0      0.995      0.895\n",
            "               class79          1          2          1          0      0.663      0.342\n",
            "Speed: 0.3ms preprocess, 8.0ms inference, 0.0ms loss, 4.7ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/val2\u001b[0m\n",
            "              model     mAP50\n",
            "0  baseline_student  0.664703\n",
            "1        kd_student  0.662932\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}